{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c5e2885",
   "metadata": {
    "id": "4c5e2885"
   },
   "outputs": [],
   "source": [
    "# ! pip install transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca0539a5",
   "metadata": {
    "id": "ca0539a5"
   },
   "outputs": [],
   "source": [
    "# df[df['content']==' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fec05ad",
   "metadata": {
    "id": "5fec05ad"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fff40ee7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fff40ee7",
    "outputId": "11c0fdd4-a78f-4d43-ed76-1abbd19e0f37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n\\nimport os\\nos.chdir('/content/drive/My Drive/')\\n\\n\\ndf=pd.read_csv('BERT_data.csv')\\ndf=df[~(df['content']=='nan')]\\ndf['content']=df['content'].astype(str)\\ndf['subject']=df['subject'].astype(str)\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive/')\n",
    "\n",
    "\n",
    "df=pd.read_csv('BERT_data.csv')\n",
    "df=df[~(df['content']=='nan')]\n",
    "df['content']=df['content'].astype(str)\n",
    "df['subject']=df['subject'].astype(str)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "862a17fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "862a17fe",
    "outputId": "6aa6d00d-cdc8-49ac-b34e-38be032d4249"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('BERT_data.csv')\n",
    "df['content']=df['content'].astype(str)\n",
    "df['subject']=df['subject'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "645c3857",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "645c3857",
    "outputId": "e0555b1d-8805-4a6e-ad56-df2c8e41d61d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, 4, 1, 6, 5, 7], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cat_1_level_2']=df['cat_1_level_2']-1\n",
    "df['cat_1_level_2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3d96f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, 4, 1, 5], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[~(df['cat_1_level_2']==6)]\n",
    "df=df[~(df['cat_1_level_2']==7)]\n",
    "df['cat_1_level_2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97659d46",
   "metadata": {
    "id": "97659d46"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.labels=df['cat_1_level_2']\n",
    "        self.text=[tokenizer(text,\n",
    "                               padding='max_length',truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['content']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.text[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c327d458",
   "metadata": {
    "id": "c327d458"
   },
   "outputs": [],
   "source": [
    "\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n",
    "                                     [int(.60*len(df)), int(.90*len(df))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "powGc726X9w-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "powGc726X9w-",
    "outputId": "5b6219c6-95e9-4b1b-996b-ad10765ed7ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.utils import resample\\nfor i in [1,2,3,4,5,6]:\\n    spam_upsample = resample(df_train[df_train['cat_1_level_2']==i],\\n             replace=True,\\n             n_samples=len(df_train[df_train['cat_1_level_2']==0]) - len(df_train[df_train['cat_1_level_2']==i]),\\n             random_state=42)\\n    df_train=pd.concat([df_train,spam_upsample])\\ndf_train.shape\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.utils import resample\n",
    "for i in [1,2,3,4,5,6]:\n",
    "    spam_upsample = resample(df_train[df_train['cat_1_level_2']==i],\n",
    "             replace=True,\n",
    "             n_samples=len(df_train[df_train['cat_1_level_2']==0]) - len(df_train[df_train['cat_1_level_2']==i]),\n",
    "             random_state=42)\n",
    "    df_train=pd.concat([df_train,spam_upsample])\n",
    "df_train.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "yDzCUBywaqK_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDzCUBywaqK_",
    "outputId": "f0c830cc-e9c2-4e35-8c9f-e7b0e6f9f5aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874 438 146\n"
     ]
    }
   ],
   "source": [
    "df_train.reset_index(inplace=True)\n",
    "df_train=df_train.drop('index',axis=1)\n",
    "\n",
    "df_val.reset_index(inplace=True)\n",
    "df_val=df_val.drop('index',axis=1)\n",
    "\n",
    "df_test.reset_index(inplace=True)\n",
    "df_test=df_test.drop('index',axis=1)\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94398b2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "94398b2e",
    "outputId": "fea30854-67bf-40fe-d713-f868c31955a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_name = \"bert-base-uncased\"\\nmodel = BertForSequenceClassification.from_pretrained(model_name, num_labels=8)\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=8)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cedf1b1",
   "metadata": {
    "id": "0cedf1b1"
   },
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.3):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 6)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50e427bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50e427bd",
    "outputId": "00e951a8-0497-4f1f-d04e-7d941be41a07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "383e6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "model = BertClassifier()\n",
    "LR = 0.0000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9734c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn=0\\nfor param in model.parameters():\\n    n=n+1\\n    param.requires_grad = False\\n    if n==117:\\n        break\\n        '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freeze first 7 layers \n",
    "'''\n",
    "n=0\n",
    "for param in model.parameters():\n",
    "    n=n+1\n",
    "    param.requires_grad = False\n",
    "    if n==117:\n",
    "        break\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72ff0c5d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "72ff0c5d",
    "outputId": "0f9a549a-7e09-4eaf-f974-3aaced2a7338"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 175/175 [01:07<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.355                 | Train Accuracy:  0.268                 | Val Loss:  0.350                 | Val Accuracy:  0.340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████████████▋                                                                                        | 43/175 [00:16<00:51,  2.56it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 71\u001b[0m\n\u001b[0;32m     61\u001b[0m                     total_acc_val \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n\u001b[0;32m     63\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     64\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_num\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss_train\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(train_data)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124m                | Train Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_acc_train\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(train_data)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124m                | Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss_val\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(val_data)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124m                | Val Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_acc_val\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(val_data)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[34], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[0;32m     26\u001b[0m n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_input, train_label \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dataloader):\n\u001b[1;32m---> 28\u001b[0m     train_label \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_label\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     mask \u001b[38;5;241m=\u001b[39m train_input[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     30\u001b[0m     input_id \u001b[38;5;241m=\u001b[39m train_input[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=5)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=5)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "            n=0\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "\n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "\n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "\n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "\n",
    "\n",
    "\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7129e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd7129e9",
    "outputId": "1f8c2c2f-cdf8-4752-d7dd-7044e816c573"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "\n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "\n",
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8f285b",
   "metadata": {
    "id": "6b8f285b"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'BERT_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170cb493",
   "metadata": {
    "id": "170cb493"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gpu1",
   "language": "python",
   "name": "gpu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
